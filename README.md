# ğŸ“Œ ASL Recognition - Deep Learning Project

## ğŸ† Objectif du projet  
Ce projet vise Ã  faciliter la communication entre les personnes pratiquant la langue des signes amÃ©ricaine (ASL) et celles qui ne la connaissent pas. Il repose sur un modÃ¨le de **Deep Learning** capable de reconnaÃ®tre les lettres de l'alphabet en **temps rÃ©el via une webcam**.

## ğŸ“‚ Bases de donnÃ©es utilisÃ©es  
Deux ensembles de donnÃ©es ont Ã©tÃ© testÃ©s pour entraÃ®ner le modÃ¨le :  

### 1. **Base de donnÃ©es 1** 
- **AccÃ¨s aux donnÃ©es** : [kaggle_bdd1](https://www.kaggle.com/datasets/grassknoted/asl-alphabet)
- **CaractÃ©ristiques** : Fond unique 
- **Objectif** : Faciliter lâ€™apprentissage du modÃ¨le  
- **Taille** : 87 000 images, 29 classes (A-Z + "del", "nothing", "space")  

### 2. **Base de donnÃ©es 2**  
- - **AccÃ¨s aux donnÃ©es** : [kaggle_bdd2](https://www.kaggle.com/datasets/lexset/synthetic-asl-alphabet)
- **CaractÃ©ristiques** : Fonds variÃ©s (nature, mur, cielâ€¦), conditions rÃ©alistes  
- **Objectif** : Tester la robustesse du modÃ¨le  
- **Taille** : 27 000 images, 27 classes (A-Z + "blank")  

## ğŸ› ï¸ PrÃ©traitement des donnÃ©es  
Les images ont subi plusieurs transformations pour optimiser lâ€™apprentissage :  
âœ… **Redimensionnement** : 128x128 pixels  
âœ… **Normalisation des pixels**  
âœ… **Division des donnÃ©es** : Train / Validation / Test  
âœ… **Batch size** : 32  

## ğŸ” ModÃ¨le et architecture  
Un **rÃ©seau de neurones convolutif (CNN) personnalisÃ©** a Ã©tÃ© conÃ§u et appliquÃ© aux deux bases de donnÃ©es.  

- **3 couches de convolution** avec :  
  - BatchNorm  
  - ReLU  
  - MaxPooling  
- **1 couche dense** de 512 neurones avec Dropout  
- **Sortie Softmax** pour la classification des classes  
- **Utilisation du GPU (`cuda`)** pour accÃ©lÃ©rer l'entraÃ®nement  

## ğŸš€ ExpÃ©rimentations et optimisations  
ğŸ”¹ **Transfert Learning** : Tests avec **AlexNet** et **VGG19** âœ…  
ğŸ”¹ **Optimisation des hyperparamÃ¨tres** (optimiseur, taux dâ€™apprentissage, fine-tuning) âŒ (aucune amÃ©lioration)  
ğŸ”¹ **Data Augmentation** âŒ (pas dâ€™amÃ©lioration)  
ğŸ”¹ **EntraÃ®nement** :  
   - 20 Ã©poques max  
   - Early Stopping pour Ã©viter lâ€™overfitting  

## ğŸ“Š RÃ©sultats et performances 
Le modÃ¨le **CNN personnalisÃ©** a obtenu des rÃ©sultats optimaux sur la **base de donnÃ©es 1 (fond blanc)** avec une **prÃ©cision de 99,2%**, tandis que les performances sur la **base 2 (fonds variÃ©s)** Ã©taient lÃ©gÃ¨rement infÃ©rieures (**96,7%**).  
Les modÃ¨les prÃ©-entraÃ®nÃ©s **AlexNet** et **VGG19** ont Ã©tÃ© testÃ©s mais ont offert des performances infÃ©rieures, notamment sur la base 2, oÃ¹ ils ont atteint **58-60% de prÃ©cision**.  

